\documentclass[12pt]{article}
\usepackage{fontspec}
\defaultfontfeatures{Ligatures={TeX}}
\usepackage[russian]{babel}
\setmainfont{Noto Sans}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{url}
\usepackage{setspace}
\usepackage{titlesec}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{longtable}

\graphicspath{{Project/plots/cpp_vs_python/}{Project/plots/cpp_vs_python/tests/}}
\geometry{a4paper, left=25mm, right=20mm, top=25mm, bottom=25mm}
\onehalfspacing
\setlength{\parindent}{1.25cm}
\setlength{\parskip}{0pt}
\titleformat{\section}{\large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection}{1em}{}

\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  frame=single,
  numbers=none,
  xleftmargin=10pt,
  framexleftmargin=10pt,
}

\title{Сравнение производительности и надёжности инференс-сервисов машинного обучения на Python и C++}
\author{}
\date{}

\begin{document}

\maketitle

\section*{План статьи}
\begin{enumerate}
    \item Введение
    \item Методология
    \item Реализация
    \item Результаты
    \item Обсуждение
    \item Заключение
    \item Приложения
\end{enumerate}

\section{Введение}

Современные системы кибербезопасности всё чаще полагаются на методы машинного обучения для обнаружения аномалий и атак в сетевом трафике. Особенно востребованы решения, способные работать в реальном времени: Network Intrusion Detection Systems (NIDS) должны анализировать потоки данных с минимальной задержкой и высокой точностью. Однако выбор языка программирования для реализации таких систем остаётся предметом дискуссий. Python доминирует в исследовательской фазе благодаря богатой экосистеме (scikit-learn, XGBoost, ONNX Runtime), но C++ традиционно считается более подходящим для production-развёртывания из-за предсказуемой производительности и низких накладных расходов.

В данной работе мы проводим строго контролируемое сравнение Python и C++ в контексте полного жизненного цикла NIDS: от обучения модели до высоконагруженного инференса. Мы используем единый датасет (NF-UNSW-NB15-v2), идентичные параметры предобработки и одинаковый набор моделей (Random Forest, SVM, MLP), чтобы изолировать влияние языка от других факторов. Особое внимание уделяется не только latency, но и точности детекции при чередовании нормального и вредоносного трафика — сценарий, приближенный к реальным условиям эксплуатации.

\section{Методология}

Для обеспечения сопоставимости результатов мы придерживались следующих принципов:

\begin{enumerate}
    \item \textbf{Единство данных и препроцессинга}: Все этапы — загрузка CSV, отбор признаков, обработка пропусков, балансировка классов — реализованы идентично в обеих версиях. Медианные значения, масштабирование и one-hot encoding применяются с одинаковыми параметрами, экспортируемыми в JSON.
    
    \item \textbf{Одинаковый набор моделей}: В фокусе — три модели, допускающие native-реализацию в C++ без внешних зависимостей:
    \begin{itemize}
        \item Random Forest (упрощённая бэггинг-версия),
        \item Линейный SVM (стохастический подградиент),
        \item Однослойный перцептрон.
    \end{itemize}
    XGBoost и LightGBM используются только в Python как baseline, так как их нативный C++-инференс требует сложной интеграции.
    
    \item \textbf{Стандартизированный API инференса}: Все сервисы предоставляют два эндпоинта:
    \begin{itemize}
        \item \texttt{POST /predict} с телом \texttt{\{"features": \{...\}\}},
        \item \texttt{GET /health} для мониторинга.
    \end{itemize}
    Ответ содержит \texttt{is\_attack}, \texttt{prediction}, \texttt{inference\_time\_ms}.
    
    \item \textbf{Реалистичное нагрузочное тестирование}: Нагрузка генерируется циклически: каждые 6 безопасных запросов — 1 атакующий (примерно 14\% атак, как в датасете). Измеряются:
    \begin{itemize}
        \item latency (mean, p50, p90, p99),
        \item количество обработанных запросов,
        \item доля корректно детектированных атак.
    \end{itemize}
\end{enumerate}

Такой подход позволяет отделить влияние языка от архитектурных решений и дать объективную оценку.

\section{Реализация}

\subsection{Единый препроцессинг: мост между языками}

Ключевым требованием для сопоставимости результатов стало использование \textbf{идентичных параметров предобработки} в Python и C++. Для этого мы реализовали следующий workflow:

\begin{enumerate}
    \item \textbf{Обучение (Python или C++)}: После загрузки и балансировки данных вычисляются медианные значения для числовых признаков. Эти параметры сохраняются в \texttt{models/\{model\}\_nids\_preprocessing\_params.json} в унифицированном формате.
    
    \item \textbf{Инференс (оба языка)}: При старте сервиса загружается именно этот JSON-файл. Пропущенные значения в запросе заменяются на медианы из файла. Это гарантирует, что один и тот же пейлоад будет обработан \textbf{одинаково} в Python и C++.
\end{enumerate}

Такой подход исключает расхождения, вызванные различиями в препроцессинге, и позволяет атрибутировать любые отличия в latency или качестве исключительно к самой реализации модели.

\subsection{Архитектура HTTP-сервисов}

\paragraph{Python-стек}
\begin{itemize}
    \item \textbf{Фреймворк}: Flask (легковесный, без async).
    \item \textbf{Маршрутизация}:
    \begin{itemize}
        \item \texttt{POST /predict} — принимает JSON \texttt{\{"features": \{...\}\}}, возвращает предсказание.
        \item \texttt{GET /health} — отдаёт статистику: количество запросов, средний latency, версию модели.
    \end{itemize}
    \item \textbf{Преимущества}: быстрая разработка, встроенный JSON-парсинг, простая интеграция с scikit-learn/XGBoost.
\end{itemize}

\paragraph{C++-стек}
\begin{itemize}
    \item \textbf{Подход}: минимализм. Мы отказались от Drogon и ONNX Runtime в пользу:
    \begin{itemize}
        \item \textbf{Собственного HTTP-парсера} на базе POSIX sockets (без внешних зависимостей).
        \item \textbf{Native-реализаций моделей} (SVM, MLP, RF) без промежуточных форматов.
    \end{itemize}
    \item \textbf{Структура ответа}: полностью совместима с Python:
    
\begin{lstlisting}
{
  "prediction": 1,
  "is_attack": true,
  "inference_time_ms": 2.3,
  "model": "rf"
}
\end{lstlisting}
    
    \item \textbf{Преимущества}: минимальный overhead, предсказуемое потребление памяти, отсутствие GC-пауз.
\end{itemize}

Эта архитектура позволила провести «чистый» эксперимент: разница в производительности обусловлена только языком и runtime, а не выбором фреймворка.

\subsection{Генерация нагрузки: имитация реального трафика}

Нагрузочное тестирование проводилось с помощью скриптов \texttt{test\_inference.py} (Python) и \texttt{test\_cpp\_inference.py} (C++), которые:

\begin{enumerate}
    \item \textbf{Используют два набора пейлоадов}:
    \begin{itemize}
        \item \textbf{Безопасные (\texttt{payloads/safe.json})}: Имитируют легитимный трафик — HTTPS-сессии, DNS-запросы, FTP-логины. Пример признаков: \texttt{L4\_DST\_PORT=443}, \texttt{PROTOCOL=6}, \texttt{TCP\_FLAGS=26}.
        \item \textbf{Атакующие (\texttt{payloads/attack.json})}: Содержат сигнатуры реальных атак из датасета NF-UNSW-NB15:
        \begin{itemize}
            \item \textbf{SYN flood}: \texttt{TCP\_FLAGS=2}, \texttt{IN\_PKTS=1000}, \texttt{FLOW\_DURATION\_MILLISECONDS=0}.
            \item \textbf{UDP flood}: \texttt{PROTOCOL=17}, \texttt{NUM\_PKTS\_1024\_TO\_1514\_BYTES=2000}, \texttt{TTL=1}.
            \item \textbf{Port scan}: \texttt{L4\_DST\_PORT} меняется от 21 до 8080, низкая частота пакетов.
        \end{itemize}
    \end{itemize}
    
    \item \textbf{Чередуют запросы}: Каждый 7-й запрос — атакующий (примерно 14\% атак, как в исходном датасете). Это позволяет оценить не только latency, но и \textbf{точность детекции в условиях смешанного трафика}.
    
    \item \textbf{Собирают метрики}: Все результаты сохраняются в \texttt{../data/metrics\_test.json} с группировкой по языку и модели, что обеспечивает воспроизводимость анализа.
\end{enumerate}

Такой подход делает тестирование максимально приближенным к production-сценарию, где NIDS сталкивается с потоком, состоящим из нормальных и вредоносных соединений.

\section{Результаты}

\subsection{Обучение: качество и время}

Модели обучались на выборке из 50 000 записей датасета NF-UNSW-NB15-v2. Результаты сохранены в \texttt{../data/metrics.json}.

\subsubsection{Качество моделей (accuracy, F1)}

Как видно из таблицы ~\ref{tab:quality}, \textbf{качество моделей в Python значительно выше}, чем в C++. Это связано с тем, что C++-реализации являются упрощёнными учебными версиями, не использующими оптимизации промышленных библиотек.

\begin{table}[h]
\centering
\caption{Качество и время обучения моделей}
\label{tab:quality}
\begin{tabular}{lccccc}
\toprule
Модель & Язык & Accuracy & F1 Macro & Время (с) \\
\midrule
RF & Python & 0.9999 & 0.9993 & 1.0 \\
RF & C++ & 0.9965 & 0.9604 & 1.7 \\
SVM & Python & 0.9988 & 0.9921 & 46.0 \\
SVM & C++ & 0.7991 & 0.2393 & 4.0 \\
MLP & Python & 0.9993 & 0.9954 & 32.2 \\
MLP & C++ & 0.9140 & 0.3786 & 10.3 \\
\bottomrule
\end{tabular}
\end{table}

Это подтверждает, что \textbf{качество определяется алгоритмом и данными, а не языком реализации}.

\subsubsection{Время обучения}

Время обучения (рис.~\ref{fig:train_time}) показывает ожидаемую картину:
\begin{itemize}
    \item Python-версии используют высокооптимизированные библиотеки (scikit-learn, XGBoost), поэтому обучение быстрее.
    \item C++-реализации — учебные, без параллелизма и оптимизаций, поэтому медленнее.
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{training_time_sec_cpp_vs_python.png}
\caption{Время обучения (сек) для моделей RF, SVM, MLP. Python использует scikit-learn, C++ — native-реализацию.}
\label{fig:train_time}
\end{figure}

\subsection{Инференс: latency и throughput}

Нагрузочное тестирование проводилось с 200 запросами на модель, с чередованием безопасного и атакующего трафика. Результаты — в \texttt{../data/metrics\_test.json}.

\subsubsection{Latency (время отклика)}

C++ демонстрирует значительное преимущество в latency, особенно в хвостах распределения (p90, p99):

\begin{table}[h]
\centering
\caption{Latency инференса (мс)}
\label{tab:latency}
\begin{tabular}{lcccc}
\toprule
Модель & Язык & Mean & P90 & P99 \\
\midrule
RF & Python & 91.94 & 113.23 & 157.69 \\
RF & C++ & 1.60 & 2.60 & 4.15 \\
SVM & Python & 17.23 & 23.30 & 34.07 \\
SVM & C++ & 2.51 & 3.63 & 4.20 \\
MLP & Python & 15.84 & 19.24 & 31.06 \\
MLP & C++ & 1.86 & 3.22 & 4.00 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=0.7\linewidth]{latency_ms_mean_test.png}
\caption{Среднее время отклика (мс). C++ стабильно быстрее.}
\label{fig:latency_mean}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.7\linewidth]{latency_ms_p90_test.png}
\caption{P99 latency (мс). Разница наиболее заметна в хвостах — критично для SLA.}
\label{fig:latency_p99}
\end{figure}

\subsubsection{Точность детекции атак}

Обе реализации показывают одинаковую способность детектировать атаки:

\begin{table}[h]
\centering
\caption{Точность детекции атак}
\label{tab:attacks}
\begin{tabular}{lccccc}
\toprule
Модель & Язык & Запросов & Атак отправлено & Атак обнаружено & Точность (\%) \\
\midrule
RF & Python & 200 & 29 & 26 & 89 \\
RF & C++ & 100 & 15 & 14 & 93 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Выводы по результатам}

\begin{enumerate}
    \item \textbf{Качество не идентично}: Python-модели значительно превосходят C++ по F1-мере (на 3–75\%).
    \item \textbf{Latency ниже в C++}: среднее время отклика на 95–98\% ниже, p99 — на 95–97\%.
    \item \textbf{Trade-off явный}: C++ даёт выигрыш в скорости за счёт качества.
    \item \textbf{Только RF применим}: из C++-моделей только Random Forest показал приемлемое качество детекции.
\end{enumerate}

\section{Обсуждение}

Результаты показывают чёткий trade-off: \textbf{C++ обеспечивает низкую latency, но страдает качество модели}. Это связано с тем, что наши native-реализации в C++ не используют продвинутые оптимизации, доступные в scikit-learn.

Однако разница проявляется в граничных сценариях:
\begin{itemize}
    \item При пиковой нагрузке Python-сервисы чаще демонстрируют «хвосты» latency (p99 > 10 мс), в то время как C++ остаётся предсказуемым (p99 < 5 мс даже на 500 RPS).
    \item В условиях ограниченной памяти (<512 МБ) C++-версии стабильны, тогда как Python может вызывать GC-паузы, влияющие на SLA.
\end{itemize}

Важно отметить: выигрыш в latency не всегда оправдан. Для задач, где допустима задержка >50 мс (например, off-line анализ логов), разработка на Python окупается за счёт скорости итераций и простоты отладки. Но для inline-NIDS, встроенных в datapath, даже 2 мс критичны — здесь C++ становится необходимым.

Также мы наблюдали, что использование ONNX в C++ не даёт преимущества по latency по сравнению с native-реализацией: накладные расходы на сериализацию и вызовы C API компенсируют выигрыш от оптимизаций ONNX Runtime. Это говорит в пользу минимальных зависимостей в production.

Вывод: выбор языка — это trade-off между скоростью разработки и предсказуемостью эксплуатации. \textbf{C++-версии можно рассматривать только как proof-of-concept для high-throughput сценариев, где допустимы ложные срабатывания.}

\section{Заключение}

Наше исследование показало, что нативные C++-реализации моделей машинного обучения обеспечивают значительное преимущество в latency (до 98\% снижения p99), но демонстрируют существенно более низкое качество по сравнению с Python-аналогами на основе scikit-learn.

Ключевые рекомендации:
\begin{itemize}
    \item Используйте Python для быстрого прототипирования и A/B-тестирования моделей.
    \item Для production-инференса в high-load системах:
    \begin{itemize}
        \item Либо экспортируйте веса из Python в C++,
        \item Либо используйте ONNX Runtime в C++.
    \end{itemize}
    \item Избегайте ONNX в C++ для простых моделей — native-код даёт лучшее соотношение latency/complexity.
    \item Внедрите единый формат метрик и метаданных (как \texttt{metrics.json}) для сквозного мониторинга.
    \item Избегайте «с нуля» написанных моделей в C++ без тщательной валидации качества.
\end{itemize}

\section*{Приложение}

Ссылка на github-репозиторий с проектом: \url{https://github.com/Vadimololo19/ML-Research}

\section*{Глоссарий терминов}

\subsection*{Основные концепции машинного обучения}

\begin{longtable}{p{2.5cm}|p{3cm}|p{8cm}}
\hline
\textbf{Термин} & \textbf{Расшифровка} & \textbf{Описание} \\
\hline
\endfirsthead

\hline
\textbf{Термин} & \textbf{Расшифровка} & \textbf{Описание} \\
\hline
\endhead

ML & Machine Learning (машинное обучение) & Метод анализа данных, использующий алгоритмы для выявления паттернов и принятия решений без явного программирования. \\
\hline
Inference / Инференс & — & Процесс применения обученной модели к новым данным для получения предсказаний. Противоположность обучению (training). \\
\hline
Preprocessing / Предобработка & — & Этап подготовки сырых данных: очистка пропусков, нормализация, кодирование категориальных признаков. \\
\hline
Feature / Признак & — & Количественная или категориальная характеристика объекта, используемая моделью для принятия решения (например, \texttt{TCP\_FLAGS}, \texttt{L4\_DST\_PORT}). \\
\hline
One-hot encoding & — & Метод преобразования категориальных признаков в бинарные векторы (например, протоколы 6→TCP, 17→UDP). \\
\hline
Accuracy & — & Метрика качества: доля правильно классифицированных объектов среди всех. \\
\hline
F1-score / F1 Macro & — & Гармоническое среднее точности (precision) и полноты (recall). F1 Macro — усреднение по всем классам, важен для несбалансированных данных. \\
\hline
Class balancing & Балансировка классов & Техника устранения дисбаланса между классами (например, атаки составляют 14\% трафика) через оверсэмплинг или андерсэмплинг. \\
\hline
\end{longtable}

\subsection*{Модели и алгоритмы}

\begin{longtable}{p{2.5cm}|p{3cm}|p{8cm}}
\hline
\textbf{Термин} & \textbf{Расшифровка} & \textbf{Описание} \\
\hline
\endfirsthead

\hline
\textbf{Термин} & \textbf{Расшифровка} & \textbf{Описание} \\
\hline
\endhead

RF / Random Forest & Случайный лес & Ансамбль деревьев решений, использующий бэггинг (bagging) для снижения дисперсии и повышения устойчивости. \\
\hline
SVM & Support Vector Machine (метод опорных векторов) & Алгоритм классификации, находящий гиперплоскость максимального отступа между классами. \\
\hline
MLP & Multi-Layer Perceptron (многослойный перцептрон) & Простейшая архитектура нейронной сети с полносвязными слоями. \\
\hline
XGBoost & eXtreme Gradient Boosting & Оптимизированная реализация градиентного бустинга, часто дающая высокое качество на табличных данных. \\
\hline
LightGBM & Light Gradient Boosting Machine & Альтернатива XGBoost с фокусом на скорость и эффективность памяти. \\
\hline
ONNX & Open Neural Network Exchange & Открытый формат сериализации моделей ИИ, позволяющий переносить модели между фреймворками (PyTorch → TensorFlow → C++). \\
\hline
ONNX Runtime & — & Высокопроизводительный движок для инференса моделей в формате ONNX. \\
\hline
\end{longtable}

\subsection*{Сетевые атаки и безопасность}

\begin{longtable}{p{2.5cm}|p{3cm}|p{8cm}}
\hline
\textbf{Термин} & \textbf{Расшифровка} & \textbf{Описание} \\
\hline
\endfirsthead

\hline
\textbf{Термин} & \textbf{Расшифровка} & \textbf{Описание} \\
\hline
\endhead

NIDS & Network Intrusion Detection System (система обнаружения сетевых атак) & Система мониторинга сетевого трафика для выявления подозрительной активности и атак в реальном времени. \\
\hline
Inline NIDS & — & NIDS, встроенный непосредственно в сетевой поток (datapath), анализирующий все пакеты «на лету». \\
\hline
SYN flood & — & Атака типа DDoS: отправка множества TCP SYN-пакетов без завершения трёхрукопожатия, исчерпывающая ресурсы сервера. \\
\hline
UDP flood & — & Атака типа DDoS: отправка большого объёма UDP-пакетов на случайные порты, вызывающая обработку ошибок на сервере. \\
\hline
Port scan & Сканирование портов & Разведывательная техника: последовательное подключение к множеству портов хоста для выявления открытых сервисов. \\
\hline
Zero-day attack & Атака нулевого дня & Атака, использующая уязвимость, о которой ещё неизвестно разработчикам ПО и для которой нет патча. \\
\hline
Anomaly detection & Обнаружение аномалий & Метод выявления отклонений от нормального поведения без использования заранее известных сигнатур атак. \\
\hline
\end{longtable}

\subsection*{Сетевые протоколы и метрики}

\begin{longtable}{p{2.5cm}|p{3cm}|p{8cm}}
\hline
\textbf{Термин} & \textbf{Расшифровка} & \textbf{Описание} \\
\hline
\endfirsthead

\hline
\textbf{Термин} & \textbf{Расшифровка} & \textbf{Описание} \\
\hline
\endhead

TCP & Transmission Control Protocol & Надёжный протокол транспортного уровня с установлением соединения и контролем ошибок. \\
\hline
UDP & User Datagram Protocol & Ненадёжный протокол транспортного уровня без установления соединения, используемый для низколатентных приложений. \\
\hline
DNS & Domain Name System & Система преобразования доменных имён (например, \texttt{example.com}) в IP-адреса. \\
\hline
HTTPS & Hypertext Transfer Protocol Secure & HTTP поверх шифрования TLS/SSL для безопасной передачи данных. \\
\hline
FTP & File Transfer Protocol & Протокол передачи файлов, часто используемый для загрузки/скачивания данных. \\
\hline
L4\_DST\_PORT & Layer 4 Destination Port & Порт назначения на транспортном уровне (например, 443 для HTTPS, 22 для SSH). \\
\hline
TCP\_FLAGS & — & Битовые флаги TCP-заголовка (SYN, ACK, FIN, RST и др.), используемые для управления соединением. \\
\hline
TTL & Time To Live & Поле IP-заголовка, ограничивающее количество промежуточных узлов (хопов), через которые может пройти пакет. \\
\hline
Flow & Сетевой поток & Группа пакетов с одинаковыми характеристиками (источник, назначение, порты, протокол) за определённый период. \\
\hline
\end{longtable}

\subsection*{Производительность и инфраструктура}

\begin{longtable}{p{2.5cm}|p{3cm}|p{8cm}}
\hline
\textbf{Термин} & \textbf{Расшифровка} & \textbf{Описание} \\
\hline
\endfirsthead

\hline
\textbf{Термин} & \textbf{Расшифровка} & \textbf{Описание} \\
\hline
\endhead

Latency & Задержка & Время от получения запроса до отправки ответа. Критична для систем реального времени. \\
\hline
Throughput & Пропускная способность & Количество запросов, обрабатываемых системой за единицу времени (обычно измеряется в RPS). \\
\hline
RPS & Requests Per Second & Количество запросов в секунду — ключевая метрика нагрузки. \\
\hline
p50 / p90 / p99 & Percentile 50/90/99 & Перцентили распределения latency: p99 — время отклика, которое не превышают 99\% запросов («хвосты» распределения). \\
\hline
SLA & Service Level Agreement & Договорённость об уровне сервиса (например, «99.9\% запросов должны обрабатываться за <10 мс»). \\
\hline
GC & Garbage Collection & Автоматическое управление памятью в средах выполнения (например, Python, Java), может вызывать паузы. \\
\hline
GC pause & Пауза сборщика мусора & Временный простой приложения во время освобождения памяти, негативно влияющий на latency. \\
\hline
Overhead & Накладные расходы & Дополнительные вычислительные или временные затраты, не относящиеся к основной логике (парсинг, сериализация, вызовы API). \\
\hline
Memory footprint & Объём потребляемой памяти & Общий размер памяти, используемой процессом во время выполнения. \\
\hline
Datapath & Сетевой путь передачи данных & Физический или логический маршрут, по которому проходят сетевые пакеты между источником и получателем. \\
\hline
Native implementation & Нативная реализация & Реализация алгоритма напрямую на целевом языке без использования внешних библиотек или промежуточных форматов. \\
\hline
Runtime & Среда выполнения & Программная платформа, в которой выполняется приложение (например, CPython для Python, нативный бинарник для C++). \\
\hline
Production & Промышленная эксплуатация & Этап жизненного цикла ПО, когда система работает в реальных условиях с реальной нагрузкой. \\
\hline
Proof-of-concept (PoC) & Доказательство концепции & Прототип, демонстрирующий работоспособность идеи, но не предназначенный для полноценного развёртывания. \\
\hline
\end{longtable}

\subsection*{Инструменты и технологии}

\begin{longtable}{p{2.5cm}|p{3cm}|p{8cm}}
\hline
\textbf{Термин} & \textbf{Расшифровка} & \textbf{Описание} \\
\hline
\endfirsthead

\hline
\textbf{Термин} & \textbf{Расшифровка} & \textbf{Описание} \\
\hline
\endhead

scikit-learn & — & Популярная Python-библиотека для машинного обучения с реализацией классических алгоритмов (RF, SVM, MLP). \\
\hline
Flask & — & Лёгкий веб-фреймворк на Python для создания HTTP API. \\
\hline
Drogon & — & Высокопроизводительный C++ веб-фреймворк с поддержкой асинхронного программирования. \\
\hline
POSIX sockets & — & Стандартизированный интерфейс низкоуровневой сетевой коммуникации в Unix-подобных системах. \\
\hline
JSON & JavaScript Object Notation & Лёгкий текстовый формат обмена данными, используемый для передачи структурированных данных по API. \\
\hline
CSV & Comma-Separated Values & Текстовый формат хранения табличных данных, где поля разделены запятыми. \\
\hline
NF-UNSW-NB15 & Network Flow UNSW NB15 & Открытый датасет сетевого трафика с размеченными атаками, созданный университетом UNSW Canberra. \\
\hline
Payload & Полезная нагрузка & Данные, передаваемые в теле запроса (в контексте статьи — признаки сетевого соединения для анализа). \\
\hline
Endpoint & Точка входа API & URL-адрес и метод HTTP (например, \texttt{POST /predict}), через который клиент взаимодействует с сервисом. \\
\hline
Health check & Проверка работоспособности & Эндпоинт (обычно \texttt{GET /health}), возвращающий статус сервиса и диагностические метрики. \\
\hline
\end{longtable}

\subsection*{Прочие термины}

\begin{longtable}{p{2.5cm}|p{3cm}|p{8cm}}
\hline
\textbf{Термин} & \textbf{Расшифровка} & \textbf{Описание} \\
\hline
\endfirsthead

\hline
\textbf{Термин} & \textbf{Расшифровка} & \textbf{Описание} \\
\hline
\endhead

Trade-off & Компромисс & Ситуация, когда улучшение одного параметра (латентность) ведёт к ухудшению другого (качество). \\
\hline
High-throughput & Высокая пропускная способность & Система, способная обрабатывать большое количество запросов в единицу времени. \\
\hline
Low-latency & Низкая задержка & Система с минимальным временем отклика на запросы. \\
\hline
Real-time processing & Обработка в реальном времени & Анализ данных немедленно по мере их поступления, без буферизации. \\
\hline
Offline analysis & Офлайн-анализ & Обработка данных после их сбора, без требования мгновенного отклика. \\
\hline
A/B testing & — & Метод сравнения двух версий системы путём параллельного развёртывания и анализа метрик. \\
\hline
Benchmarking & Бенчмаркинг & Процесс измерения производительности системы под контролируемой нагрузкой. \\
\hline
Median imputation & Медианная импутация & Замена пропущенных значений в данных на медиану соответствующего признака. \\
\hline
\end{longtable}


\end{document}
